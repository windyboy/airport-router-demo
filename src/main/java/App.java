
import org.apache.kafka.common.serialization.Serde;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.kstream.Consumed;
import org.apache.kafka.streams.kstream.KStream;
import org.apache.kafka.streams.kstream.KTable;
import org.apache.kafka.streams.kstream.Produced;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Properties;

/*
 * This Java source file was generated by the Gradle 'init' task.
 */
public class App {

    private static Logger log = LoggerFactory.getLogger(App.class.getName());

    private static String brokers = "193.112.49.204:9092";

    private static String inputTopic = "aodb";

    private static String routeTopic = "route";


    private static void buildForSystem(Properties streamsConfiguration, StreamsBuilder builder, String subsystem) {

        log.info("building router for system - " + subsystem);

        final Serde<String> stringSerde = Serdes.String();

        KTable<String, String> routeTable = builder
                .table(routeTopic, Consumed.with(stringSerde, stringSerde))
                .filter((route, system) -> {
                            log.debug("rid:"+route+", systems:"+system);
                            boolean flag = system == null ? false : system.toLowerCase().contains(subsystem.toLowerCase());
                            if (flag) log.info(system+" got ["+route+"]");
                            return flag;
                        }
                );


        KStream<String, String> messageStream = builder.stream(inputTopic, Consumed.with(stringSerde, stringSerde))
                .selectKey((k, v) -> k)
                .join(routeTable, (msg, route) -> {
                            log.debug(subsystem  + " get  - "+ route);
                            return msg;
                        }
                );


        messageStream.to(subsystem, Produced.with(stringSerde, stringSerde));

        final KafkaStreams streams = new KafkaStreams(builder.build(), streamsConfiguration);
        streams.cleanUp();
        streams.start();
        Runtime.getRuntime().addShutdownHook(new Thread(streams::close));
    }

    public static void main(String[] args) {
        final String target = args.length > 0 ? args[0] : "FIMS";
        final String myBrookers = args.length > 1 ? args[1] : brokers;
        final String appId = target + "-router";
        final String clientId = target + "-client";
        final Properties streamsConfiguration = new Properties();
        // Give the Streams application a unique name.  The name must be unique in the Kafka cluster
        // against which the application is run.
        streamsConfiguration.put(StreamsConfig.APPLICATION_ID_CONFIG, appId);
        streamsConfiguration.put(StreamsConfig.CLIENT_ID_CONFIG, clientId);
        // Where to find Kafka broker(s).
        streamsConfiguration.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, myBrookers);
        // Specify default (de)serializers for record keys and for record values.
        streamsConfiguration.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName());
        streamsConfiguration.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName());

        streamsConfiguration.put("auto.offset.reset", "earliest");

        final StreamsBuilder builder = new StreamsBuilder();
        buildForSystem(streamsConfiguration, builder, target);
    }

}
